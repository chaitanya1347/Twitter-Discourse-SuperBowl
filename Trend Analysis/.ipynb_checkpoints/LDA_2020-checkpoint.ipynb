{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a626fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# libraries for visualization\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe3ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= pd.read_csv(\"C:\\\\Users\\CHAITANYA AGRAWAL\\\\OneDrive - IIT Delhi\\\\Desktop\\\\Projects\\\\Toronto\\\\Scraping the data\\\\Final script and data\\\\US\\\\US_2020.csv\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_words_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d892ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['power', 'amp', 'superbowl', 'time', 'heartbroken', 'chiefskingdom', 'chief']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']): \n",
    "       output = []\n",
    "       for sent in texts:\n",
    "             doc = nlp(sent) \n",
    "             output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
    "       return output\n",
    "\n",
    "def preprocessing_text(table):\n",
    "    #put everythin in lowercase\n",
    "    table['text'] = table['text'].str.lower()\n",
    "    #Fix contractions\n",
    "    #table['text'] = table['text'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "    #remove stopwords\n",
    "    table['text'] = table['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words_list)]))\n",
    "    #Replace rt indicating that was a retweet\n",
    "    #table['text'] = table['text'].str.replace('rt', '')\n",
    "    #Replace occurences of mentioning @UserNames\n",
    "    table['text'] = table['text'].replace(r'@\\w+', '', regex=True)\n",
    "    #Replace links contained in the tweet\n",
    "    table['text'] = table['text'].replace(r'http\\S+', '', regex=True)\n",
    "    table['text'] = table['text'].replace(r'www.[^ ]+', '', regex=True)\n",
    "    #remove numbers\n",
    "    table['text'] = table['text'].replace(r'[0-9]+', '', regex=True)\n",
    "    #replace special characters and puntuation marks\n",
    "    table['text'] = table['text'].replace(r'[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~]', '', regex=True)\n",
    "    return table\n",
    "\n",
    "preprocessing_text(data1)\n",
    "text_list_1=data1['text'].tolist()\n",
    "tokenized_reviews_1 = lemmatization(text_list_1)\n",
    "print(tokenized_reviews_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049cb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_1 = corpora.Dictionary(tokenized_reviews_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e87138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix_1 = [dictionary_1.doc2bow(rev) for rev in tokenized_reviews_1]\n",
    "\n",
    "# Creating the object for LDA model using gensim library\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model_1 = LDA(corpus=doc_term_matrix_1, id2word=dictionary_1, num_topics=10, random_state=100,update_every=1,\n",
    "                chunksize=100, passes=50,iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73184c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.091*\"part\" + 0.040*\"enough\" + 0.015*\"center\" + 0.014*\"joke\" + 0.012*\"art\" + 0.011*\"past\" + 0.009*\"meme\" + 0.009*\"lesson\" + 0.008*\"cup\" + 0.008*\"sauce\"'),\n",
       " (1,\n",
       "  '0.144*\"superbowl\" + 0.099*\"halftime\" + 0.083*\"show\" + 0.049*\"day\" + 0.041*\"year\" + 0.034*\"next\" + 0.032*\"commercial\" + 0.029*\"fan\" + 0.021*\"good\" + 0.019*\"first\"'),\n",
       " (2,\n",
       "  '0.130*\"super\" + 0.125*\"bowl\" + 0.054*\"people\" + 0.027*\"week\" + 0.024*\"thing\" + 0.023*\"weekend\" + 0.020*\"way\" + 0.018*\"happy\" + 0.015*\"night\" + 0.014*\"‚ù§\"'),\n",
       " (3,\n",
       "  '0.048*\"white\" + 0.038*\"dance\" + 0.032*\"hour\" + 0.023*\"song\" + 0.022*\"ticket\" + 0.019*\"patrickmahome\" + 0.017*\"‚úî\" + 0.015*\"üòç\" + 0.015*\"hip\" + 0.012*\"beautiful\"'),\n",
       " (4,\n",
       "  '0.225*\"super\" + 0.221*\"bowl\" + 0.026*\"chief\" + 0.025*\"year\" + 0.013*\"party\" + 0.012*\"performance\" + 0.012*\"national\" + 0.012*\"anthem\" + 0.011*\"game\" + 0.010*\"er\"'),\n",
       " (5,\n",
       "  '0.042*\"superbowlliv\" + 0.039*\"man\" + 0.030*\"work\" + 0.029*\"lot\" + 0.027*\"rock\" + 0.026*\"hard\" + 0.025*\"city\" + 0.023*\"sport\" + 0.017*\"little\" + 0.015*\"home\"'),\n",
       " (6,\n",
       "  '0.079*\"team\" + 0.070*\"great\" + 0.063*\"last\" + 0.038*\"guy\" + 0.036*\"woman\" + 0.029*\"video\" + 0.025*\"coach\" + 0.023*\"eagle\" + 0.021*\"many\" + 0.019*\"real\"'),\n",
       " (7,\n",
       "  '0.056*\"football\" + 0.049*\"favorite\" + 0.049*\"love\" + 0.038*\"event\" + 0.027*\"much\" + 0.020*\"bet\" + 0.019*\"coverage\" + 0.017*\"cowboy\" + 0.017*\"call\" + 0.017*\"u\"'),\n",
       " (8,\n",
       "  '0.141*\"time\" + 0.060*\"ad\" + 0.034*\"parade\" + 0.031*\"amazing\" + 0.030*\"world\" + 0.027*\"lol\" + 0.027*\"kid\" + 0.023*\"full\" + 0.019*\"fun\" + 0.017*\"black\"'),\n",
       " (9,\n",
       "  '0.077*\"amp\" + 0.077*\"half\" + 0.047*\"superbowl\" + 0.035*\"thank\" + 0.027*\"chiefskingdom\" + 0.026*\"üèº\" + 0.025*\"tomorrow\" + 0.024*\"üëè\" + 0.017*\"üî•\" + 0.014*\"folk\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_1.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762ff5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model_1, corpus=doc_term_matrix_1, texts=tokenized_reviews_1):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,10), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model_1, corpus=doc_term_matrix_1, texts=tokenized_reviews_1 )\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4cc918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.619997</td>\n",
       "      <td>super, bowl, chief, year, party, performance, ...</td>\n",
       "      <td>[super, bowl, party, part]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.586792</td>\n",
       "      <td>amp, half, superbowl, thank, chiefskingdom, üèº,...</td>\n",
       "      <td>[power, amp, superbowl, time, heartbroken, chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.427634</td>\n",
       "      <td>superbowl, halftime, show, day, year, next, co...</td>\n",
       "      <td>[cheap, pizza, beer, super, bowl, night, life,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>super, bowl, chief, year, party, performance, ...</td>\n",
       "      <td>[super, bowl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.366668</td>\n",
       "      <td>amp, half, superbowl, thank, chiefskingdom, üèº,...</td>\n",
       "      <td>[thank, ‚ù§]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14943</th>\n",
       "      <td>14943</td>\n",
       "      <td>4</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>super, bowl, chief, year, party, performance, ...</td>\n",
       "      <td>[super, bowl, commercial, lol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14944</th>\n",
       "      <td>14944</td>\n",
       "      <td>9</td>\n",
       "      <td>0.439320</td>\n",
       "      <td>amp, half, superbowl, thank, chiefskingdom, üèº,...</td>\n",
       "      <td>[question, schlock, superbowl, half, time, sure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14945</th>\n",
       "      <td>14945</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198250</td>\n",
       "      <td>superbowl, halftime, show, day, year, next, co...</td>\n",
       "      <td>[enough, brother, half, time, show, woman, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14946</th>\n",
       "      <td>14946</td>\n",
       "      <td>8</td>\n",
       "      <td>0.513895</td>\n",
       "      <td>time, ad, parade, amazing, world, lol, kid, fu...</td>\n",
       "      <td>[fking, ad, super, bowl, ad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14947</th>\n",
       "      <td>14947</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>part, enough, center, joke, art, past, meme, l...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14948 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0                0               4            0.619997   \n",
       "1                1               9            0.586792   \n",
       "2                2               1            0.427634   \n",
       "3                3               4            0.699993   \n",
       "4                4               9            0.366668   \n",
       "...            ...             ...                 ...   \n",
       "14943        14943               4            0.420000   \n",
       "14944        14944               9            0.439320   \n",
       "14945        14945               1            0.198250   \n",
       "14946        14946               8            0.513895   \n",
       "14947        14947               0            0.100000   \n",
       "\n",
       "                                                Keywords  \\\n",
       "0      super, bowl, chief, year, party, performance, ...   \n",
       "1      amp, half, superbowl, thank, chiefskingdom, üèº,...   \n",
       "2      superbowl, halftime, show, day, year, next, co...   \n",
       "3      super, bowl, chief, year, party, performance, ...   \n",
       "4      amp, half, superbowl, thank, chiefskingdom, üèº,...   \n",
       "...                                                  ...   \n",
       "14943  super, bowl, chief, year, party, performance, ...   \n",
       "14944  amp, half, superbowl, thank, chiefskingdom, üèº,...   \n",
       "14945  superbowl, halftime, show, day, year, next, co...   \n",
       "14946  time, ad, parade, amazing, world, lol, kid, fu...   \n",
       "14947  part, enough, center, joke, art, past, meme, l...   \n",
       "\n",
       "                                                    Text  \n",
       "0                             [super, bowl, party, part]  \n",
       "1      [power, amp, superbowl, time, heartbroken, chi...  \n",
       "2      [cheap, pizza, beer, super, bowl, night, life,...  \n",
       "3                                          [super, bowl]  \n",
       "4                                             [thank, ‚ù§]  \n",
       "...                                                  ...  \n",
       "14943                     [super, bowl, commercial, lol]  \n",
       "14944   [question, schlock, superbowl, half, time, sure]  \n",
       "14945  [enough, brother, half, time, show, woman, but...  \n",
       "14946                       [fking, ad, super, bowl, ad]  \n",
       "14947                                                 []  \n",
       "\n",
       "[14948 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07378592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.871126</td>\n",
       "      <td>part, enough, center, joke, art, past, meme, lesson, cup, sauce</td>\n",
       "      <td>[hace, americana, pura, visto, se√±ora, doblemoral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.871427</td>\n",
       "      <td>superbowl, halftime, show, day, year, next, commercial, fan, good, first</td>\n",
       "      <td>[superbowl, halftime, show, terrible, next, day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.899998</td>\n",
       "      <td>super, bowl, people, week, thing, weekend, way, happy, night, ‚ù§</td>\n",
       "      <td>[super, bowl, üò≠, üò≠, üò≠, üò≠, üò≠, üò≠]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.864936</td>\n",
       "      <td>white, dance, hour, song, ticket, patrickmahome, ‚úî, üòç, hip, beautiful</td>\n",
       "      <td>[dice, mil, d√≥lare, por, solo, tocar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>super, bowl, chief, year, party, performance, national, anthem, game, er</td>\n",
       "      <td>[election, year, playoff, election, year, playoff, game, election, year, super, bowl, election, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.850715</td>\n",
       "      <td>superbowlliv, man, work, lot, rock, hard, city, sport, little, home</td>\n",
       "      <td>[legend, celebrity, celebration, hard, rock, longlivelove]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.777287</td>\n",
       "      <td>team, great, last, guy, woman, video, coach, eagle, many, real</td>\n",
       "      <td>[missy, music, rap, producer, choreographer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.888124</td>\n",
       "      <td>football, favorite, love, event, much, bet, coverage, cowboy, call, u</td>\n",
       "      <td>[vote, ummm, üßê, üßê, üßê, üßê, üßê, üßê]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.765412</td>\n",
       "      <td>time, ad, parade, amazing, world, lol, kid, full, fun, black</td>\n",
       "      <td>[backpack, br, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.872143</td>\n",
       "      <td>amp, half, superbowl, thank, chiefskingdom, üèº, tomorrow, üëè, üî•, folk</td>\n",
       "      <td>[superbowl, goodness, amp, üî•, üî•, üî•, üî•, üî•, üî•, üî•, üî•, üî•, üî•, üî•, fucken, good]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0          0            0.871126   \n",
       "1          1            0.871427   \n",
       "2          2            0.899998   \n",
       "3          3            0.864936   \n",
       "4          4            0.935707   \n",
       "5          5            0.850715   \n",
       "6          6            0.777287   \n",
       "7          7            0.888124   \n",
       "8          8            0.765412   \n",
       "9          9            0.872143   \n",
       "\n",
       "                                                                   Keywords  \\\n",
       "0           part, enough, center, joke, art, past, meme, lesson, cup, sauce   \n",
       "1  superbowl, halftime, show, day, year, next, commercial, fan, good, first   \n",
       "2           super, bowl, people, week, thing, weekend, way, happy, night, ‚ù§   \n",
       "3     white, dance, hour, song, ticket, patrickmahome, ‚úî, üòç, hip, beautiful   \n",
       "4  super, bowl, chief, year, party, performance, national, anthem, game, er   \n",
       "5       superbowlliv, man, work, lot, rock, hard, city, sport, little, home   \n",
       "6            team, great, last, guy, woman, video, coach, eagle, many, real   \n",
       "7     football, favorite, love, event, much, bet, coverage, cowboy, call, u   \n",
       "8              time, ad, parade, amazing, world, lol, kid, full, fun, black   \n",
       "9       amp, half, superbowl, thank, chiefskingdom, üèº, tomorrow, üëè, üî•, folk   \n",
       "\n",
       "                                                                                   Representative Text  \n",
       "0                                                   [hace, americana, pura, visto, se√±ora, doblemoral]  \n",
       "1                                                     [superbowl, halftime, show, terrible, next, day]  \n",
       "2                                                                      [super, bowl, üò≠, üò≠, üò≠, üò≠, üò≠, üò≠]  \n",
       "3                                                                [dice, mil, d√≥lare, por, solo, tocar]  \n",
       "4  [election, year, playoff, election, year, playoff, game, election, year, super, bowl, election, ...  \n",
       "5                                           [legend, celebrity, celebration, hard, rock, longlivelove]  \n",
       "6                                                         [missy, music, rap, producer, choreographer]  \n",
       "7                                                                       [vote, ummm, üßê, üßê, üßê, üßê, üßê, üßê]  \n",
       "8                                                                                 [backpack, br, time]  \n",
       "9                            [superbowl, goodness, amp, üî•, üî•, üî•, üî•, üî•, üî•, üî•, üî•, üî•, üî•, üî•, fucken, good]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f56247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
