{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e342da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# libraries for visualization\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c18c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= pd.read_csv(\"C:\\\\Users\\CHAITANYA AGRAWAL\\\\OneDrive - IIT Delhi\\\\Desktop\\\\Projects\\\\Toronto\\\\Scraping the data\\\\Final script and data\\\\US\\\\US_2021.csv\")\n",
    "from nltk.corpus import stopwords\n",
    "stop_words_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f58342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excited', 'teacher', 'cheerleader', 'student']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']): \n",
    "       output = []\n",
    "       for sent in texts:\n",
    "             doc = nlp(sent) \n",
    "             output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
    "       return output\n",
    "\n",
    "def preprocessing_text(table):\n",
    "    #put everythin in lowercase\n",
    "    table['text'] = table['text'].str.lower()\n",
    "    #Fix contractions\n",
    "    #table['text'] = table['text'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "    #remove stopwords\n",
    "    table['text'] = table['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words_list)]))\n",
    "    #Replace rt indicating that was a retweet\n",
    "    #table['text'] = table['text'].str.replace('rt', '')\n",
    "    #Replace occurences of mentioning @UserNames\n",
    "    table['text'] = table['text'].replace(r'@\\w+', '', regex=True)\n",
    "    #Replace links contained in the tweet\n",
    "    table['text'] = table['text'].replace(r'http\\S+', '', regex=True)\n",
    "    table['text'] = table['text'].replace(r'www.[^ ]+', '', regex=True)\n",
    "    #remove numbers\n",
    "    table['text'] = table['text'].replace(r'[0-9]+', '', regex=True)\n",
    "    #replace special characters and puntuation marks\n",
    "    table['text'] = table['text'].replace(r'[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~]', '', regex=True)\n",
    "    return table\n",
    "\n",
    "preprocessing_text(data1)\n",
    "text_list_1=data1['text'].tolist()\n",
    "tokenized_reviews_1 = lemmatization(text_list_1)\n",
    "print(tokenized_reviews_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51219cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_1 = corpora.Dictionary(tokenized_reviews_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71f046df",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix_1 = [dictionary_1.doc2bow(rev) for rev in tokenized_reviews_1]\n",
    "\n",
    "# Creating the object for LDA model using gensim library\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model_1 = LDA(corpus=doc_term_matrix_1, id2word=dictionary_1, num_topics=10, random_state=100,update_every=1,\n",
    "                chunksize=100, passes=50,iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fad355e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.185*\"bowl\" + 0.183*\"super\" + 0.071*\"year\" + 0.041*\"chief\" + 0.029*\"ad\" + 0.022*\"champion\" + 0.014*\"shit\" + 0.011*\"life\" + 0.011*\"champ\" + 0.009*\"work\"'),\n",
       " (1,\n",
       "  '0.280*\"super\" + 0.278*\"bowl\" + 0.034*\"good\" + 0.030*\"team\" + 0.028*\"time\" + 0.013*\"buccaneer\" + 0.013*\"football\" + 0.009*\"weekend\" + 0.007*\"many\" + 0.007*\"history\"'),\n",
       " (2,\n",
       "  '0.116*\"people\" + 0.083*\"fan\" + 0.053*\"bad\" + 0.042*\"man\" + 0.040*\"today\" + 0.033*\"bucs\" + 0.031*\"coach\" + 0.020*\"medium\" + 0.020*\"stadium\" + 0.018*\"free\"'),\n",
       " (3,\n",
       "  '0.055*\"party\" + 0.036*\"mask\" + 0.030*\"top\" + 0.028*\"state\" + 0.024*\"🇸\" + 0.023*\"low\" + 0.023*\"number\" + 0.020*\"ball\" + 0.017*\"hope\" + 0.016*\"case\"'),\n",
       " (4,\n",
       "  '0.124*\"game\" + 0.058*\"thing\" + 0.037*\"big\" + 0.028*\"tv\" + 0.025*\"event\" + 0.024*\"point\" + 0.023*\"last\" + 0.021*\"🏆\" + 0.019*\"lot\" + 0.018*\"reason\"'),\n",
       " (5,\n",
       "  '0.055*\"way\" + 0.042*\"much\" + 0.026*\"loss\" + 0.025*\"whole\" + 0.023*\"superbowllv\" + 0.020*\"🏾\" + 0.019*\"post\" + 0.015*\"smh\" + 0.014*\"ready\" + 0.013*\"one\"'),\n",
       " (6,\n",
       "  '0.061*\"halftime\" + 0.059*\"show\" + 0.056*\"next\" + 0.045*\"mahome\" + 0.034*\"week\" + 0.033*\"performance\" + 0.031*\"sport\" + 0.026*\"love\" + 0.020*\"streaker\" + 0.018*\"line\"'),\n",
       " (7,\n",
       "  '0.185*\"superbowl\" + 0.045*\"last\" + 0.029*\"year\" + 0.028*\"win\" + 0.026*\"amp\" + 0.022*\"ring\" + 0.021*\"guy\" + 0.017*\"rating\" + 0.016*\"well\" + 0.014*\"money\"'),\n",
       " (8,\n",
       "  '0.113*\"commercial\" + 0.112*\"great\" + 0.033*\"second\" + 0.031*\"home\" + 0.027*\"little\" + 0.021*\"lv\" + 0.019*\"moment\" + 0.015*\"different\" + 0.015*\"flag\" + 0.012*\"check\"'),\n",
       " (9,\n",
       "  '0.076*\"night\" + 0.074*\"day\" + 0.054*\"season\" + 0.035*\"first\" + 0.031*\"part\" + 0.030*\"yesterday\" + 0.029*\"field\" + 0.018*\"beach\" + 0.017*\"parade\" + 0.016*\"right\"')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_1.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8fa193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model_1, corpus=doc_term_matrix_1, texts=tokenized_reviews_1):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,10), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model_1, corpus=doc_term_matrix_1, texts=tokenized_reviews_1 )\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68e580b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.700402</td>\n",
       "      <td>halftime, show, next, mahome, week, performance, sport, love, streaker, line</td>\n",
       "      <td>[superbowl, week, enough, attention, fact, entire, professional, sport, team, due, covid, protocol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775570</td>\n",
       "      <td>bowl, super, year, chief, ad, champion, shit, life, champ, work</td>\n",
       "      <td>[excited, teacher, cheerleader, student]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820218</td>\n",
       "      <td>super, bowl, good, team, time, buccaneer, football, weekend, many, history</td>\n",
       "      <td>[good, evening, dante, super, bowl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.470985</td>\n",
       "      <td>game, thing, big, tv, event, point, last, 🏆, lot, reason</td>\n",
       "      <td>[super, bowl, takeout, wing, special, lbs, bone, lb, boneless, takeout, mix, kitchen, order, wing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775329</td>\n",
       "      <td>super, bowl, good, team, time, buccaneer, football, weekend, many, history</td>\n",
       "      <td>[tenth, super, bowl, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16881</th>\n",
       "      <td>16881</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619995</td>\n",
       "      <td>super, bowl, good, team, time, buccaneer, football, weekend, many, history</td>\n",
       "      <td>[super, bowl, w, cowboy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16882</th>\n",
       "      <td>16882</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294637</td>\n",
       "      <td>super, bowl, good, team, time, buccaneer, football, weekend, many, history</td>\n",
       "      <td>[dak, super, bowl, ring, first, cowboy, dak]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16883</th>\n",
       "      <td>16883</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619999</td>\n",
       "      <td>super, bowl, good, team, time, buccaneer, football, weekend, many, history</td>\n",
       "      <td>[event, super, bowl, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16884</th>\n",
       "      <td>16884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584032</td>\n",
       "      <td>bowl, super, year, chief, ad, champion, shit, life, champ, work</td>\n",
       "      <td>[divisional, round, super, bowl, fucking, guy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>16885</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524995</td>\n",
       "      <td>super, bowl, good, team, time, buccaneer, football, weekend, many, history</td>\n",
       "      <td>[night, super, bowl]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16886 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0                0               6            0.700402   \n",
       "1                1               0            0.775570   \n",
       "2                2               1            0.820218   \n",
       "3                3               4            0.470985   \n",
       "4                4               1            0.775329   \n",
       "...            ...             ...                 ...   \n",
       "16881        16881               1            0.619995   \n",
       "16882        16882               1            0.294637   \n",
       "16883        16883               1            0.619999   \n",
       "16884        16884               0            0.584032   \n",
       "16885        16885               1            0.524995   \n",
       "\n",
       "                                                                           Keywords  \\\n",
       "0      halftime, show, next, mahome, week, performance, sport, love, streaker, line   \n",
       "1                   bowl, super, year, chief, ad, champion, shit, life, champ, work   \n",
       "2        super, bowl, good, team, time, buccaneer, football, weekend, many, history   \n",
       "3                          game, thing, big, tv, event, point, last, 🏆, lot, reason   \n",
       "4        super, bowl, good, team, time, buccaneer, football, weekend, many, history   \n",
       "...                                                                             ...   \n",
       "16881    super, bowl, good, team, time, buccaneer, football, weekend, many, history   \n",
       "16882    super, bowl, good, team, time, buccaneer, football, weekend, many, history   \n",
       "16883    super, bowl, good, team, time, buccaneer, football, weekend, many, history   \n",
       "16884               bowl, super, year, chief, ad, champion, shit, life, champ, work   \n",
       "16885    super, bowl, good, team, time, buccaneer, football, weekend, many, history   \n",
       "\n",
       "                                                                                                      Text  \n",
       "0      [superbowl, week, enough, attention, fact, entire, professional, sport, team, due, covid, protocol]  \n",
       "1                                                                 [excited, teacher, cheerleader, student]  \n",
       "2                                                                      [good, evening, dante, super, bowl]  \n",
       "3       [super, bowl, takeout, wing, special, lbs, bone, lb, boneless, takeout, mix, kitchen, order, wing]  \n",
       "4                                                                            [tenth, super, bowl, weekend]  \n",
       "...                                                                                                    ...  \n",
       "16881                                                                             [super, bowl, w, cowboy]  \n",
       "16882                                                         [dak, super, bowl, ring, first, cowboy, dak]  \n",
       "16883                                                                        [event, super, bowl, weekend]  \n",
       "16884                                                       [divisional, round, super, bowl, fucking, guy]  \n",
       "16885                                                                                 [night, super, bowl]  \n",
       "\n",
       "[16886 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "867e4f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.906416</td>\n",
       "      <td>bowl, super, year, chief, ad, champion, shit, life, champ, work</td>\n",
       "      <td>[glory, tgbtg, 🏼, congratulation, super, bowl, champ, 🙏, 🏼]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.949999</td>\n",
       "      <td>super, bowl, good, team, time, buccaneer, football, weekend, many, history</td>\n",
       "      <td>[super, super, super, super, super, super, super, super, super, super, super, super, super, supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.769534</td>\n",
       "      <td>people, fan, bad, man, today, bucs, coach, medium, stadium, free</td>\n",
       "      <td>[rocket, mortgage, ®, superbowl, square, sweepstake, chance, big, super, bowl, score, change, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.866875</td>\n",
       "      <td>party, mask, top, state, 🇸, low, number, ball, hope, case</td>\n",
       "      <td>[party, spam, oven, potato, wedge, cheesy, focaccia, bread, marinara]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.777851</td>\n",
       "      <td>game, thing, big, tv, event, point, last, 🏆, lot, reason</td>\n",
       "      <td>[sound, superspreader, event, crossconnection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.774992</td>\n",
       "      <td>way, much, loss, whole, superbowllv, 🏾, post, smh, ready, one</td>\n",
       "      <td>[ready, kelce, pat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.874109</td>\n",
       "      <td>halftime, show, next, mahome, week, performance, sport, love, streaker, line</td>\n",
       "      <td>[fresh, road, tap, keyword, theater, friday‼️, newmovie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.943745</td>\n",
       "      <td>superbowl, last, year, win, amp, ring, guy, rating, well, money</td>\n",
       "      <td>[🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, superbowl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.774995</td>\n",
       "      <td>commercial, great, second, home, little, lv, moment, different, flag, check</td>\n",
       "      <td>[home, lv, gobuc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.796822</td>\n",
       "      <td>night, day, season, first, part, yesterday, field, beach, parade, right</td>\n",
       "      <td>[existence, positive, affirmation, beach]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0          0            0.906416   \n",
       "1          1            0.949999   \n",
       "2          2            0.769534   \n",
       "3          3            0.866875   \n",
       "4          4            0.777851   \n",
       "5          5            0.774992   \n",
       "6          6            0.874109   \n",
       "7          7            0.943745   \n",
       "8          8            0.774995   \n",
       "9          9            0.796822   \n",
       "\n",
       "                                                                       Keywords  \\\n",
       "0               bowl, super, year, chief, ad, champion, shit, life, champ, work   \n",
       "1    super, bowl, good, team, time, buccaneer, football, weekend, many, history   \n",
       "2              people, fan, bad, man, today, bucs, coach, medium, stadium, free   \n",
       "3                     party, mask, top, state, 🇸, low, number, ball, hope, case   \n",
       "4                      game, thing, big, tv, event, point, last, 🏆, lot, reason   \n",
       "5                 way, much, loss, whole, superbowllv, 🏾, post, smh, ready, one   \n",
       "6  halftime, show, next, mahome, week, performance, sport, love, streaker, line   \n",
       "7               superbowl, last, year, win, amp, ring, guy, rating, well, money   \n",
       "8   commercial, great, second, home, little, lv, moment, different, flag, check   \n",
       "9       night, day, season, first, part, yesterday, field, beach, parade, right   \n",
       "\n",
       "                                                                                   Representative Text  \n",
       "0                                          [glory, tgbtg, 🏼, congratulation, super, bowl, champ, 🙏, 🏼]  \n",
       "1  [super, super, super, super, super, super, super, super, super, super, super, super, super, supe...  \n",
       "2  [rocket, mortgage, ®, superbowl, square, sweepstake, chance, big, super, bowl, score, change, gr...  \n",
       "3                                [party, spam, oven, potato, wedge, cheesy, focaccia, bread, marinara]  \n",
       "4                                                       [sound, superspreader, event, crossconnection]  \n",
       "5                                                                                  [ready, kelce, pat]  \n",
       "6                                             [fresh, road, tap, keyword, theater, friday‼️, newmovie]  \n",
       "7                                                [🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, 🖤, superbowl]  \n",
       "8                                                                                    [home, lv, gobuc]  \n",
       "9                                                            [existence, positive, affirmation, beach]  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3863f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
